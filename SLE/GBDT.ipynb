{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c946ce5-28e8-4c30-a428-f42fa849bebd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-03T14:09:14.544894Z",
     "start_time": "2025-02-03T14:09:14.534493Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be484562-9169-4f10-8534-21380740928c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score, f1_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0316c91a-23dd-46e9-b9b5-0b9fe89b1b5a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-03T14:09:14.704239Z",
     "start_time": "2025-02-03T14:09:14.700076Z"
    }
   },
   "outputs": [],
   "source": [
    "seed = 563453451"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a465c2cc-1c9e-4b59-9460-50c901e66e14",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-03T14:09:15.313222Z",
     "start_time": "2025-02-03T14:09:15.288879Z"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "X_ini = train.iloc[:,1:17]\n",
    "y_ini = train.iloc[:,17]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7284436c-40c2-44fb-bddb-825905936b56",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-03T14:09:15.313222Z",
     "start_time": "2025-02-03T14:09:15.288879Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      0\n",
       "2      0\n",
       "3      0\n",
       "4      0\n",
       "      ..\n",
       "307    1\n",
       "308    1\n",
       "309    1\n",
       "310    1\n",
       "311    1\n",
       "Name: Type, Length: 312, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "X_ini\n",
    "y_ini\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ec93c569-6cdc-423e-acd5-9774a918d0c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-03T14:09:15.463803Z",
     "start_time": "2025-02-03T14:09:15.458732Z"
    }
   },
   "outputs": [],
   "source": [
    "sp = RepeatedStratifiedKFold(random_state=seed,n_repeats=3,n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3490f203-6076-4792-a3b5-b1f97a1ae053",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-03T14:09:16.026551Z",
     "start_time": "2025-02-03T14:09:15.581172Z"
    }
   },
   "outputs": [],
   "source": [
    "import hyperopt\n",
    "from hyperopt import hp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "34db2882-861e-4cca-b89f-7153afd213c5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-03T14:09:16.040215Z",
     "start_time": "2025-02-03T14:09:16.030088Z"
    }
   },
   "outputs": [],
   "source": [
    "def objective(param):\n",
    "    aucs = []\n",
    "    for train_index,test_index in sp.split(X_ini,y_ini):\n",
    "        X_train = X_ini.iloc[train_index,:]\n",
    "        X_vali = X_ini.iloc[test_index,:]\n",
    "        y_train = y_ini[train_index]\n",
    "        y_vali = y_ini[test_index]\n",
    "        model = GradientBoostingClassifier(random_state=seed,\n",
    "                                           n_estimators=param['n_estimators'],\n",
    "                                           max_depth=param['max_depth'],\n",
    "                                           min_samples_split=param['min_samples_split'],\n",
    "                                           min_samples_leaf=param['min_samples_leaf'],\n",
    "                                           learning_rate=param['learning_rate'])\n",
    "        model.fit(X_train,y_train)\n",
    "        pro_vali = model.predict_proba(X_vali)[:,1]\n",
    "        auc_vali = roc_auc_score(y_vali,pro_vali)\n",
    "        aucs.append(auc_vali)\n",
    "    return -np.mean(aucs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0a8169f3-a03f-476d-bb7a-0f2bd064fcff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-03T14:09:16.235567Z",
     "start_time": "2025-02-03T14:09:16.228564Z"
    }
   },
   "outputs": [],
   "source": [
    "#超参数搜索范围，根据数据集不同进行修改\n",
    "space = {\n",
    "    'n_estimators':hp.choice('n_estimators',range(2,50)),\n",
    "    'max_depth':hp.choice('max_depth',range(1,3)),\n",
    "    'min_samples_split':hp.choice('min_samples_split',range(2,50)),\n",
    "    'min_samples_leaf':hp.choice('min_samples_leaf',range(2,50)),\n",
    "    'learning_rate':hp.uniform('learning_rate',0,1)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "65b227e7-5324-4cf8-9d0a-e6d08582b22c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-03T14:09:54.806764Z",
     "start_time": "2025-02-03T14:09:16.588305Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████| 100/100 [00:50<00:00,  2.00trial/s, best loss: -1.0]\n"
     ]
    }
   ],
   "source": [
    "best_param = hyperopt.fmin(objective,space,hyperopt.tpe.suggest,max_evals=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "381d6386-5113-4f3c-8fdb-ceef5083c558",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-03T14:10:32.053678Z",
     "start_time": "2025-02-03T14:10:32.042833Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.3499476786928011,\n",
       " 'max_depth': 1,\n",
       " 'min_samples_leaf': 9,\n",
       " 'min_samples_split': 47,\n",
       " 'n_estimators': 21}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "78f8e1b0-142a-45c8-a90f-bc9c38f256e6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-03T14:10:34.792576Z",
     "start_time": "2025-02-03T14:10:34.764722Z"
    }
   },
   "outputs": [],
   "source": [
    "#这里注意range()范围与上面的搜索空间保持一致\n",
    "model = GradientBoostingClassifier(random_state=seed,\n",
    "                                   n_estimators=range(2,50)[best_param['n_estimators']],\n",
    "                                   max_depth=range(1,3)[best_param['max_depth']],\n",
    "                                   min_samples_split=range(2,50)[best_param['min_samples_split']],\n",
    "                                   min_samples_leaf=range(2,50)[best_param['min_samples_leaf']],\n",
    "                                   learning_rate=best_param['learning_rate'])\n",
    "model.fit(X_ini,y_ini)\n",
    "pro_train = model.predict_proba(X_ini)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cc56eaa6-90f3-42b1-8bbb-1985423622ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-03T14:10:36.141224Z",
     "start_time": "2025-02-03T14:10:36.128655Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集AUC=1.000\n"
     ]
    }
   ],
   "source": [
    "print('训练集AUC={:.3f}'.format(roc_auc_score(y_ini,pro_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "22e8be92-10d4-4cc7-bcde-3cf34c6f200e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-03T14:10:45.731645Z",
     "start_time": "2025-02-03T14:10:45.721824Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train = pd.DataFrame({\n",
    "    'ID':train['ID'],\n",
    "    'True':y_ini,\n",
    "    'Pre':pro_train\n",
    "})\n",
    "df_train.to_csv('GBDT_train.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "aa2e686e-0b3a-4361-aae1-9a37d02cee4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用模型对训练集数据进行预测，得到预测标签\n",
    "y_pred_train = model.predict(X_ini)  \n",
    "\n",
    "# 计算训练集的AUC值（需要模型输出的概率值 pro_train）\n",
    "auc_train = roc_auc_score(y_ini, pro_train)\n",
    "\n",
    "# 计算训练集准确率（正确预测样本比例）\n",
    "accuracy_train = accuracy_score(y_ini, y_pred_train)\n",
    "\n",
    "# 计算训练集精确率（预测为正的样本中真实为正的比例）\n",
    "precision_train = precision_score(y_ini, y_pred_train)\n",
    "\n",
    "# 计算训练集召回率（真实为正的样本中被正确预测的比例）\n",
    "recall_train = recall_score(y_ini, y_pred_train)\n",
    "\n",
    "# 计算训练集F1分数（精确率和召回率的调和平均数）\n",
    "f1_train = f1_score(y_ini, y_pred_train)\n",
    "\n",
    "# 生成训练集的混淆矩阵（四分类表格）\n",
    "confusion_train = confusion_matrix(y_ini, y_pred_train)\n",
    "\n",
    "# 解构混淆矩阵四个值：真阴、假阳、假阴、真阳\n",
    "tn, fp, fn, tp = confusion_train.ravel()\n",
    "\n",
    "# 计算特异度（真实为负的样本中被正确识别的比例）\n",
    "specificity_train = tn / (tn + fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d6ca1ee9-6a88-4a10-8f98-8f88035ba96e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集AUC=1.000\n",
      "训练集Accuracy=1.000\n",
      "训练集Precision=1.000\n",
      "训练集Sensitivity (Recall)=1.000\n",
      "训练集Specificity=1.000\n",
      "训练集F1=1.000\n"
     ]
    }
   ],
   "source": [
    "print('训练集AUC={:.3f}'.format(auc_train))\n",
    "print('训练集Accuracy={:.3f}'.format(accuracy_train))\n",
    "print('训练集Precision={:.3f}'.format(precision_train))\n",
    "print('训练集Sensitivity (Recall)={:.3f}'.format(recall_train))\n",
    "print('训练集Specificity={:.3f}'.format(specificity_train))\n",
    "print('训练集F1={:.3f}'.format(f1_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "eb11529f-cafe-4705-9cc8-3ce7fbc20168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for test1.csv:\n",
      "测试集 AUC = 0.574\n",
      "测试集 Accuracy = 0.401\n",
      "测试集 Precision = 0.401\n",
      "测试集 Sensitivity (Recall) = 0.991\n",
      "测试集 Specificity = 0.006\n",
      "测试集 F1 = 0.571\n",
      "\n",
      "Results for test2.csv:\n",
      "测试集 AUC = 0.451\n",
      "测试集 Accuracy = 0.471\n",
      "测试集 Precision = 0.471\n",
      "测试集 Sensitivity (Recall) = 1.000\n",
      "测试集 Specificity = 0.000\n",
      "测试集 F1 = 0.640\n",
      "\n",
      "Results for test3.csv:\n",
      "测试集 AUC = 0.484\n",
      "测试集 Accuracy = 0.676\n",
      "测试集 Precision = 0.676\n",
      "测试集 Sensitivity (Recall) = 1.000\n",
      "测试集 Specificity = 0.000\n",
      "测试集 F1 = 0.807\n",
      "\n",
      "Results for test4.csv:\n",
      "测试集 AUC = 0.481\n",
      "测试集 Accuracy = 0.887\n",
      "测试集 Precision = 0.887\n",
      "测试集 Sensitivity (Recall) = 1.000\n",
      "测试集 Specificity = 0.000\n",
      "测试集 F1 = 0.940\n",
      "\n",
      "Results for test5.csv:\n",
      "测试集 AUC = 0.384\n",
      "测试集 Accuracy = 0.753\n",
      "测试集 Precision = 0.753\n",
      "测试集 Sensitivity (Recall) = 1.000\n",
      "测试集 Specificity = 0.000\n",
      "测试集 F1 = 0.859\n",
      "\n",
      "Results for test6.csv:\n",
      "测试集 AUC = 0.521\n",
      "测试集 Accuracy = 0.767\n",
      "测试集 Precision = 0.767\n",
      "测试集 Sensitivity (Recall) = 1.000\n",
      "测试集 Specificity = 0.000\n",
      "测试集 F1 = 0.868\n",
      "\n",
      "Results for test7.csv:\n",
      "测试集 AUC = 0.499\n",
      "测试集 Accuracy = 0.928\n",
      "测试集 Precision = 0.928\n",
      "测试集 Sensitivity (Recall) = 1.000\n",
      "测试集 Specificity = 0.000\n",
      "测试集 F1 = 0.963\n",
      "\n",
      "Results for test8.csv:\n",
      "测试集 AUC = 0.415\n",
      "测试集 Accuracy = 0.846\n",
      "测试集 Precision = 0.846\n",
      "测试集 Sensitivity (Recall) = 1.000\n",
      "测试集 Specificity = 0.000\n",
      "测试集 F1 = 0.917\n"
     ]
    }
   ],
   "source": [
    "# 导入必要库\n",
    "import pandas as pd\n",
    "from sklearn.metrics import (roc_auc_score, accuracy_score, \n",
    "                           precision_score, recall_score, \n",
    "                           f1_score, confusion_matrix)\n",
    "\n",
    "# 定义测试集文件列表（简化路径）\n",
    "test_files = [\n",
    "    'test1.csv',\n",
    "    'test2.csv',\n",
    "    'test3.csv',\n",
    "    'test4.csv',\n",
    "    'test5.csv',\n",
    "    'test6.csv',\n",
    "    'test7.csv',\n",
    "    'test8.csv'\n",
    "]\n",
    "\n",
    "# 遍历每个测试集文件\n",
    "for test_file in test_files:\n",
    "    # 数据加载\n",
    "    test = pd.read_csv(test_file)  # 读取CSV文件\n",
    "    \n",
    "    # 特征工程\n",
    "    X_test = test.iloc[:, 1:17]   # 提取第2到第10列作为特征（假设第1列为ID）\n",
    "    y_test = test.iloc[:, 17]     # 提取第11列作为真实标签\n",
    "    \n",
    "    # 模型预测\n",
    "    pro_test = model.predict_proba(X_test)[:, 1]  # 获取正类预测概率\n",
    "    y_pred_test = model.predict(X_test)           # 获取预测标签（0/1分类）\n",
    "    \n",
    "    # 计算评估指标\n",
    "    auc_test = roc_auc_score(y_test, pro_test)          # AUC面积\n",
    "    accuracy_test = accuracy_score(y_test, y_pred_test)  # 准确率\n",
    "    precision_test = precision_score(y_test, y_pred_test) # 精确率\n",
    "    recall_test = recall_score(y_test, y_pred_test)       # 召回率/敏感度\n",
    "    f1_test = f1_score(y_test, y_pred_test)              # F1分数\n",
    "    \n",
    "    # 混淆矩阵分析\n",
    "    confusion_test = confusion_matrix(y_test, y_pred_test)  # 生成混淆矩阵\n",
    "    tn, fp, fn, tp = confusion_test.ravel()                # 解构四类结果\n",
    "    specificity_test = tn / (tn + fp)                      # 计算特异度\n",
    "    \n",
    "    # 输出评估结果\n",
    "    print(f'\\nResults for {test_file}:')\n",
    "    print(f'测试集 AUC = {auc_test:.3f}')                   \n",
    "    print(f'测试集 Accuracy = {accuracy_test:.3f}')         \n",
    "    print(f'测试集 Precision = {precision_test:.3f}')       \n",
    "    print(f'测试集 Sensitivity (Recall) = {recall_test:.3f}')\n",
    "    print(f'测试集 Specificity = {specificity_test:.3f}')   \n",
    "    print(f'测试集 F1 = {f1_test:.3f}')                     \n",
    "    \n",
    "    # 保存预测结果\n",
    "    df_test = pd.DataFrame({\n",
    "        'ID': test['ID'],       # 保留原始ID列\n",
    "        'True': y_test,          # 真实标签\n",
    "        'Pre': pro_test          # 预测概率值\n",
    "    })\n",
    "    df_test.to_csv(f'GBDT_{test_file}_predictions.csv', index=False)  # 生成预测文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fb698e77-671b-4f2a-a3fa-78a14faa54a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型已保存到当前目录下的 GBDT_model.joblib\n"
     ]
    }
   ],
   "source": [
    "# 保存模型\n",
    "import joblib\n",
    "\n",
    "model_filename = 'GBDT_model.joblib'\n",
    "joblib.dump(model, model_filename)  # 这里model需要是已训练好的模型对象\n",
    "print(f\"模型已保存到当前目录下的 {model_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e37531-e781-4a9d-9c1c-efd198ca25a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
